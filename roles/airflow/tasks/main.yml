---

- name: create airflow user
  user:
    name: airflow
    comment: "Airflow user"
    shell: /bin/bash
  tags: airflow

- name: set up authorized_keys for airflow user
  authorized_key: user=airflow key="{{ lookup('file', 'public_keys/' + item + '_id_rsa.pub') }}"
  with_items: "{{ ['hadoop'] + airflow_admins }}"
  tags: airflow

- name: assert dfs /user/airflow dir exists
  shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -ls /user/airflow
  register: assert_user_airflow_dir_exists
  changed_when: no
  ignore_errors: yes
  tags: airflow

- name: create dfs /user/airflow dir
  shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -mkdir -p /user/airflow &&
         /usr/local/hadoop-2.9.2/bin/hdfs dfs -chown airflow:supergroup /user/airflow
  when: assert_user_airflow_dir_exists is failed
  become: yes
  become_user: hadoop
  tags: airflow

- name: better bash history for 'airflow' user
  blockinfile:
    dest: /home/airflow/.bashrc
    mode: 0644
    marker: "# {mark} ANSIBLE MANAGED BLOCK airflow-history"
    block: |
      HISTFILESIZE=20000
      HISTSIZE=10000
      HISTTIMEFORMAT='%y-%m-%dT%T  '
  become: yes
  become_user: airflow
  tags: airflow

- name: create ~/airflow_home directory
  file:
    path: /home/airflow/airflow_home
    state: directory
  become: yes
  become_user: airflow
  tags: airflow

- name: template airflow config
  template:
    src: airflow.cfg.j2
    dest: /home/airflow/airflow_home/airflow.cfg
  become: yes
  become_user: airflow
  notify:
    - airflow initdb
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow

- name: checkout code base
  git:
    repo: https://github.com/mblomdahl/o3.git
    version: feature/conda
    dest: /home/airflow/o3
    accept_hostkey: yes
  become: yes
  become_user: airflow
  tags: airflow

- name: upload anaconda3 installer
  copy:
    src: resources/Anaconda3-5.2.0-Linux-x86_64.sh
    dest: /tmp/Anaconda3-5.2.0-Linux-x86_64.sh
    owner: airflow
    group: airflow
    mode: 0755
  tags: airflow

- name: run anaconda3 installer
  shell: /tmp/Anaconda3-5.2.0-Linux-x86_64.sh -b -f -s
  args:
    creates: /home/airflow/anaconda3
  become: yes
  become_user: airflow
  tags: airflow

- name: anaconda3 shell setup
  blockinfile:
    dest: /home/airflow/.bashrc
    marker: "# {mark} ANSIBLE MANAGED BLOCK airflow-anaconda3"
    block: |
      . /home/airflow/anaconda3/etc/profile.d/conda.sh
  become: yes
  become_user: airflow
  tags: airflow

- name: create ~/.conda/pkgs
  file:
    path: /home/airflow/{{ item }}
    state: directory
  become: yes
  become_user: airflow
  with_items:
    - .conda
    - .conda/pkgs
  register: dot_conda_dirs
  tags: airflow

- name: create ~/.conda/environments.txt
  file:
    path: /home/airflow/.conda/environments.txt
    state: touch
    mode: 0664
  become: yes
  become_user: airflow
  when: dot_conda_dirs is changed
  tags: airflow

- name: create airflow conda virtualenv
  shell: bash -l -c '/home/airflow/anaconda3/bin/conda
         create --name o3 --yes python=3.6'
  args:
    creates: /home/airflow/anaconda3/envs/o3
  become: yes
  become_user: airflow
  register: conda_o3_env
  tags: airflow

- name: install spec-file-linux
  shell: bash -l -c 'conda activate o3 && conda install --name o3
         --file ~/o3/spec-file-linux.txt'
  become: yes
  become_user: airflow
  when: conda_o3_env is changed
  tags: airflow

- name: install pip requirements.txt
  shell: bash -l -c 'conda activate o3 && SLUGIFY_USES_TEXT_UNIDECODE=yes
         pip install -r /home/airflow/o3/requirements.txt'
  become: yes
  become_user: airflow
  register: o3_pip_install_requirements
  changed_when: "'Successfully ' in o3_pip_install_requirements.stdout"
  notify:
    - airflow initdb
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow


- name: template airflow-environment
  template:
    src: environment.j2
    dest: /home/airflow/airflow-environment
  become: yes
  become_user: airflow
  notify:
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow

- name: source airflow-environment in {{ bash_profile_file }}
  blockinfile:
    path: /home/airflow/{{ bash_profile_file }}
    marker: "# {mark} ANSIBLE MANAGED BLOCK airflow-environment"
    block: |
      set -a
      source /home/airflow/airflow-environment
      export PATH=/usr/local/hadoop-2.9.2/bin:/usr/local/hadoop-2.9.2/sbin:$PATH
      export JAVA_HOME={{ java_home }}
  become: yes
  become_user: airflow
  tags: airflow

- name: start postgres database
  docker_container:
    name: airflow_postgres
    image: postgres:9.6
    state: started
    restart_policy: unless-stopped
    volume_driver: local
    volumes:
      - airflow_postgres:/var/lib/postgresql/data
    ports:
      - 5432:5432
    env:
      POSTGRES_DB: airflow
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: "{{ airflow_db_user_password }}"
  tags: airflow

- name: template airflow services
  template:
    src: airflow-{{ item }}.service.j2
    dest: /etc/systemd/system/airflow-{{ item }}.service
  with_items:
    - webserver
    - scheduler
  register: add_airflow_services
  notify:
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow

- name: run daemon-reload on airflow services
  shell: systemctl daemon-reload
  when: add_airflow_services is changed
  tags: airflow

- name: set airflow services to running and auto-starting
  service:
    name: airflow-{{ item }}
    state: started
    enabled: yes
  with_items:
    - webserver
    - scheduler
  tags: airflow

...
